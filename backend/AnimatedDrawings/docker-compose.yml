version: '3'

services:
  animated_drawings:
    build:
      context: torchserve
      dockerfile: Dockerfile
    container_name: docker_torchserve
    ports:
      - "8080:8080"
    networks:
      - aiary

  ai_backend:
    container_name: ai_backend
    build:
      dockerfile: Dockerfile
    environment:
      FLASK_ENV: development
      FLASK_DEBUG: 1
    command: conda run -n animated_drawings gunicorn -w 5 -b 0.0.0.0:8000 wsgi:app
      --log-level=debug
      --access-logfile /app/gunicorn/access.log
      --error-logfile /app/gunicorn/error.log
    restart: unless-stopped
    networks:
      - aiary

  nginx:
    container_name: nginx
    build:
      context: ./nginx
      dockerfile: Dockerfile
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/log:/var/log/nginx
    expose:
      - 80
    depends_on:
      - ai_backend
    networks:
      - aiary

  ai_rabbitmq:
    hostname: rabbit
    container_name: ai_rabbitmq
    image: rabbitmq:3-management
    command: rabbitmq-server
    restart: unless-stopped
    environment:
      - RABBITMQ_USER=guest
      - RABBITMQ_PASSWORD=guest
    ports:
      - "5672:5672" # Default Port
      - "15672:15672" # For UI
    depends_on:
      - ai_backend
    networks:
      - aiary
    expose:
      - "15672"

  ai_celery:
    container_name: ai_celery
    build:
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      - ai_backend
      - ai_rabbitmq
    networks:
      - aiary
    command: conda run -n animated_drawings celery -A tasks.celery worker --loglevel=debug --pool threads --logfile=/app/celery/celery.log

  ai_redis:
    container_name: ai_redis
    image: redis:alpine
    command: redis-server --port 6000
    ports:
      - "6000:6000"
    networks:
      - aiary

networks:
  aiary:
    driver: bridge